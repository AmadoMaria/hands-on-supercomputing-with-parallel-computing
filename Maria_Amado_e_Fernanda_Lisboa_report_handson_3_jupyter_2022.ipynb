{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmadoMaria/hands-on-supercomputing-with-parallel-computing/blob/master/Maria_Amado_e_Fernanda_Lisboa_report_handson_3_jupyter_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXATwZ8VxZG7",
        "tags": []
      },
      "source": [
        "# Hands-on 3: Portable Parallel Programming with MPI\n",
        "\n",
        "M. Amado$^1$, F. Lisboa$^1$\n",
        "\n",
        "$^1$ Department of Computer Engenier – University SENAI CIMATEC, Salvador, Bahia, Brazil  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5PcGb-Pt0_j"
      },
      "source": [
        "# Abstract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orxl23v_xqVe"
      },
      "source": [
        "A paralelização da execução de tarefas, como operações matemáticas, tem sido aplicadas no dia-a-dia. Há algumas formas de aplicar esse mecanismo em código, seja por memória compartilhada ou distribuída. O presente trabalho busca aplicar os conceitos de memória distribuída, utilizando MPI (Message Passing Information) em algoritmos que realizem operações algébricas e matemáticas. Isso é feito utilizando as principais funções dessa biblioteca (_send_ e _receive_), onde é possível perceber que com uma maior quantidade de dados e valores de entrada a paralelização é mais eficiente na execução de operações como o cálculo: operações matemáticas simples; funções polinomiais; e, diagonal principal, subdiagonal e superdiagonal. Sendo assim, é visualizada a importância da utilização desse mecanismo, mesmo em cálculos do cotidiano."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGlWZ-SlQObx"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngiuqnkbvTdx"
      },
      "source": [
        "A paralelização na computação se refere a múltiplas instruções e tipos de dados e envolve decomposição do domínio como um modo de particionar da carga de trabalho [1]. Há diversas operações matemáticas que possuem alto grau de paralelismo [1], aplicadas no dia-a-dia. Em computadores comuns, sem aplicação de alguma técnica de paralelismo, a medida que os valores dessas operações matemáticas vão crescendo, aumenta-se o tempo de execução desses algoritmos, já que é feito de maneira sequencial. A paralelização surge como um método para reduzir esse tempo de execução, sobretudo para valores e volumes de dados mais altos. Esse procedimento lida com partículas de mudanças em ambos domínio e competência de processadores [2], sendo uma das principais bases  a abordagem \"dividir para conquistar\" [1].\n",
        "\n",
        "\n",
        "A comunicação entre os processos pode ser feita através de mensagens através de memória compartilhada ou distribuída. Dentro desse cenário surge o MPI (Messsage Passing Interface), o qual diversos processos paralelos trabalham concorrentemente em busca de um objetivo comum utilizando \"mensagens\" entre si [1]. O MPI possui uma coleção de funções, sendo suas principais de envio e recebimento de informações entre os processos. \n",
        "\n",
        "O presente trabalho tem como objetivo otimizar a execução de algoritmos de operações algébricas e matemátricas utilizando conceitos de memória distribuída. Assim, são realizados alguns problemas abordados nessas áreas, utilizando a biblioteca do MPI para aplicar esse paradigma de paralelização como uma forma de otimizar o tempo de execução dos algoritmos. Os problemas são dividos nas seguintes sessões: *basic operations*, abordando a paralelização para operações básicas como soma, subtração e múltiplicação de elementos de um *array*; *algebraic function*, trazendo o cálculo de uma função polinomial de 3º grau para dado os valores de seus coeficientes e um *x* em questão; e, *trigiagonal matrix*, abordando a soma dos valores da diagonal principal, subdiagonal e superdiagonal de uma matriz quadrada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWbtdBgpwXeJ"
      },
      "source": [
        "# Results and Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalando o MPI:"
      ],
      "metadata": {
        "id": "EhtpwlhTv0uW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "5lEryygpFNiI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install openmpi-bin\n",
        "clear_output(wait=False)"
      ],
      "metadata": {
        "id": "2NMWPyUsv0Dl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56kMBoGq8FSA"
      },
      "source": [
        "### Session 1: Basic Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ_FG9Nzwdjc"
      },
      "source": [
        "Nessa sessão trabalhamos com a paralelização utilizando conceitos de memória distribuída para operações básicas como adição, subtração e multiplicação em um array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdj9EdYH4RMS"
      },
      "source": [
        "A partir de uma função generalizada, obtemos o valor resultante da operação. Além disso, essa modificação promoveu apenas um envio, ao invés de dois (operação e valor), e decidiu-se utilizar o id do processo como identificador da operação que seria realizada. A lógica utilizada nessa implementação foi replicada nas demais sessões, sempre enviando os dados em forma de array ou matriz e associando os processos a posição do array correspondente."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código sequencial."
      ],
      "metadata": {
        "id": "i_6uf54OF6II"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x0GUUYfcX47h",
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6caa6edd-48b7-4a7c-bd19-7a9b2089f5e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing op.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile op.c\n",
        "#include <stdio.h>\n",
        "#include <mpi.h>\n",
        "#define SIZE 12\n",
        "\n",
        "int getOperationResult (char operation, int array[SIZE])\n",
        "{\n",
        "  int value;\n",
        "  switch (operation)\n",
        "  {\n",
        "  case '+':\n",
        "    value = 0;\n",
        "    for (int i = 0; i < SIZE; i++)\n",
        "      value += array[i];\n",
        "    break;\n",
        "  case '-':\n",
        "    value = 0;\n",
        "    for (int i = 0; i < SIZE; i++)\n",
        "      value -= array[i];\n",
        "    break;\n",
        "  case '*':\n",
        "    value = 1;\n",
        "    for (int i = 0; i < SIZE; i++)\n",
        "      value *= array[i];\n",
        "    break;\n",
        "  }\n",
        "  return value;\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "  int i, sum = 0, subtraction = 0, mult = 1, result, value;\n",
        "  int array[SIZE];\n",
        "  char ops[] = {'+', '-', '*'};\n",
        "  char operationsRec;\n",
        "  int numberProcess, id, to, from, tag = 1000;\n",
        "\n",
        "  MPI_Init(&argc, &argv);\n",
        "  MPI_Comm_rank(MPI_COMM_WORLD, &id);\n",
        "  MPI_Comm_size(MPI_COMM_WORLD, &numberProcess);\n",
        "  MPI_Status status;\n",
        "\n",
        "  if (id == 0)\n",
        "  {\n",
        "    for (i = 0; i < SIZE; i++)\n",
        "    {\n",
        "      array[i] = i + 1;\n",
        "      printf(\"%d %d\\t\", i, array[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "    for (to = 1; to < numberProcess; to++)\n",
        "    {\n",
        "      MPI_Send(&array, SIZE, MPI_INT, to, tag, MPI_COMM_WORLD);\n",
        "      MPI_Send(&ops[to - 1], 1, MPI_CHAR, to, tag, MPI_COMM_WORLD);\n",
        "    }\n",
        "\n",
        "    for (to = 1; to < numberProcess; to++)\n",
        "    {\n",
        "      MPI_Recv(&result, 1, MPI_INT, to, tag, MPI_COMM_WORLD, &status);\n",
        "      MPI_Recv(&operationsRec, 1, MPI_CHAR, to, tag, MPI_COMM_WORLD, &status);\n",
        "      printf(\"(%c) = %d\\n\", operationsRec, result);\n",
        "    }\n",
        "  }\n",
        "  else\n",
        "  {\n",
        "    MPI_Recv(&array, SIZE, MPI_INT, 0, tag, MPI_COMM_WORLD, &status);\n",
        "    MPI_Recv(&operationsRec, 1, MPI_CHAR, 0, tag, MPI_COMM_WORLD, &status);\n",
        "\n",
        "    value = getOperationResult(operationsRec, array);\n",
        "\n",
        "    MPI_Send(&value, 1, MPI_INT, 0, tag, MPI_COMM_WORLD);\n",
        "    MPI_Send(&operationsRec, 1, MPI_CHAR, 0, tag, MPI_COMM_WORLD);\n",
        "  }\n",
        "\n",
        "  MPI_Finalize();\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc op.c -o obj\n",
        "!mpirun --allow-run-as-root --np 4 ./obj "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhbNIdUetxcY",
        "outputId": "c1dc3427-8575-4322-cf8a-1067dd1468df"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1\t1 2\t2 3\t3 4\t4 5\t5 6\t6 7\t7 8\t8 9\t9 10\t10 11\t11 12\t\n",
            "(+) = 78\n",
            "(-) = -78\n",
            "(*) = 479001600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código com a utilização de paralelização usando memória distribuída."
      ],
      "metadata": {
        "id": "a9cSr9pSF49Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile basic_opt.c\n",
        "#include <stdio.h>\n",
        "#include <mpi.h>\n",
        "#define SIZE 12\n",
        "\n",
        "int getOperationResult(int operation, int array[SIZE])\n",
        "{\n",
        "    int value;\n",
        "    switch (operation)\n",
        "    {\n",
        "    case 1:\n",
        "        value = 0;\n",
        "        for (int i = 0; i < SIZE; i++)\n",
        "            value += array[i];\n",
        "        break;\n",
        "    case 2:\n",
        "        value = 0;\n",
        "        for (int i = 0; i < SIZE; i++)\n",
        "            value -= array[i];\n",
        "        break;\n",
        "    case 3:\n",
        "        value = 1;\n",
        "        for (int i = 0; i < SIZE; i++)\n",
        "            value *= array[i];\n",
        "        break;\n",
        "    }\n",
        "    return value;\n",
        "}\n",
        "\n",
        "char getOperation(int id)\n",
        "{\n",
        "    switch (id)\n",
        "    {\n",
        "    case 1:\n",
        "        return '+';\n",
        "    case 2:\n",
        "        return '-';\n",
        "    case 3:\n",
        "        return '*';\n",
        "    default:\n",
        "        break;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    int i, sum = 0, subtraction = 0, mult = 1, result, value;\n",
        "    int array[SIZE];\n",
        "    int numberProcess, id, to, from, tag = 1000;\n",
        "\n",
        "    MPI_Init(&argc, &argv);\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &id);\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &numberProcess);\n",
        "    MPI_Status status;\n",
        "\n",
        "    if (id == 0)\n",
        "    {\n",
        "        for (i = 0; i < SIZE; i++)\n",
        "        {\n",
        "            array[i] = i + 1;\n",
        "            printf(\"%d %d\\t\", i, array[i]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "        for (to = 1; to < numberProcess; to++)\n",
        "        {\n",
        "            MPI_Send(&array, SIZE, MPI_INT, to, tag, MPI_COMM_WORLD);\n",
        "        }\n",
        "\n",
        "        for (from = 1; from < numberProcess; from++)\n",
        "        {\n",
        "            MPI_Recv(&result, 1, MPI_INT, from, tag, MPI_COMM_WORLD, &status);\n",
        "            char operation = getOperation(from);\n",
        "            printf(\"(%c) = %d\\n\", operation, result);\n",
        "        }\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        MPI_Recv(&array, SIZE, MPI_INT, 0, tag, MPI_COMM_WORLD, &status);\n",
        "\n",
        "        for (int j = 1; j < numberProcess; j++)\n",
        "        {\n",
        "            if (id == j)\n",
        "            {\n",
        "                value = getOperationResult(id, array);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        MPI_Send(&value, 1, MPI_INT, 0, tag, MPI_COMM_WORLD);\n",
        "    }\n",
        "\n",
        "    MPI_Finalize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "QHjxNzZ2p6OR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7988bbd-d871-4f4f-89fb-9167d6799e21"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing basic_opt.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc basic_opt.c -o obj\n",
        "!mpirun --allow-run-as-root --np 4 ./obj "
      ],
      "metadata": {
        "id": "6Ca8v2oFZPsP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081d065a-5539-42ec-8bdf-ac18a12bd8b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1\t1 2\t2 3\t3 4\t4 5\t5 6\t6 7\t7 8\t8 9\t9 10\t10 11\t11 12\t\n",
            "(+) = 78\n",
            "(-) = -78\n",
            "(*) = 479001600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Session 2: Algebraic Function"
      ],
      "metadata": {
        "id": "-7lxT5Mlrfx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Já nessa sessão, a paralelização é feita para funções polinomiais."
      ],
      "metadata": {
        "id": "_4wW6w5vwLEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código sequencial."
      ],
      "metadata": {
        "id": "YYEUcOIaF2VP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile obj.c\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "int main (int argc, char **argv){\n",
        "\n",
        "  double coefficient[4], total, x;\n",
        "  char c;\n",
        "\n",
        "  printf (\"\\nf(x) = a*x^3 + b*x^2 + c*x + d\\n\");\n",
        "\n",
        "  for(c = 'a'; c < 'e'; c++) {\n",
        "    printf (\"\\nEnter the value of the 'constants' %c:\\n\", c);\n",
        "    scanf (\"%lf\", &coefficient[c - 'a']);\n",
        "  }\n",
        "\n",
        "  printf(\"\\nf(x) = %lf*x^3 + %lf*x^2 + %lf*x + %lf\\n\", coefficient[0], coefficient[1], coefficient[2], coefficient[3]);\n",
        "\n",
        "  printf(\"\\nEnter the value of 'x':\\n\");\n",
        "  scanf(\"%lf\", &x);\n",
        "\n",
        "  total = (coefficient[0]* x * x * x) + (coefficient[1]* x * x) + (coefficient[2]* x + coefficient[3]);\n",
        "\n",
        "  printf(\"\\nf(%lf) = %lf*x^3 + %lf*x^2 + %lf*x + %lf = %lf\\n\", x, coefficient[0], coefficient[1], coefficient[2], coefficient[3], total);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q63eLDI-zRfA",
        "outputId": "b0dcbd54-9ed7-49b4-f56e-5a625e16cf59"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing obj.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc obj.c -o obj\n",
        "! ./obj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcRafZS2ze73",
        "outputId": "a0e42932-7e2f-4ed1-8ecc-5b3793b345dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "f(x) = a*x^3 + b*x^2 + c*x + d\n",
            "\n",
            "Enter the value of the 'constants' a:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código com a utilização de paralelização usando memória distribuída."
      ],
      "metadata": {
        "id": "3352hBHgF02J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile algebraic.c\n",
        "#include <stdio.h>\n",
        "#include <mpi.h>\n",
        "#define SIZE 5\n",
        "\n",
        "double getOperationResult(int processIndex, double array[SIZE])\n",
        "{\n",
        "  double term;\n",
        "  double x = array[0];\n",
        "  switch (processIndex)\n",
        "  {\n",
        "  case 1:\n",
        "    term = (x * x * x) * array[1];\n",
        "    break;\n",
        "  case 2:\n",
        "    term = (x * x) * array[2];\n",
        "    break;\n",
        "  case 3:\n",
        "    term = x * array[3] + array[4];\n",
        "    break;\n",
        "  }\n",
        "  return term;\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    int i;\n",
        "    double result, value, x, total = 0;\n",
        "    double array[SIZE];\n",
        "    int numberProcess, id, to, from, tag = 1000;\n",
        "\n",
        "    MPI_Init(&argc, &argv);\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &id);\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &numberProcess);\n",
        "    MPI_Status status;\n",
        "\n",
        "    if (id == 0)\n",
        "    {\n",
        "        char c;\n",
        "        array[1] = 40; //a\n",
        "        array[2] = 20; //b\n",
        "        array[3] = 10; //c\n",
        "        array[4] = 1;  //d\n",
        "\n",
        "        printf(\"\\nf(x)=%lf*x^3+%lf*x^2+%lf*x+%lf\\n\", array[1], array[2], array[3], array[4]);\n",
        "        //printf(\"\\nEnter the value of ’x’:\\n\");\n",
        "        //scanf(\"%lf\", &x);\n",
        "        array[0] = 2; //x\n",
        "\n",
        "        for (to = 1; to < numberProcess; to++)\n",
        "        {\n",
        "            MPI_Send(&array, SIZE, MPI_DOUBLE, to, tag, MPI_COMM_WORLD);\n",
        "        }\n",
        "\n",
        "        for (from = 1; from < numberProcess; from++)\n",
        "        {\n",
        "            MPI_Recv(&result, 1, MPI_DOUBLE, from, tag, MPI_COMM_WORLD, &status);\n",
        "            total = total + result;\n",
        "        }\n",
        "        printf(\"\\nf(%lf) = %lf*x^3 + %lf*x^2 + %lf*x + %lf = %lf\\n\", array[0], array[1], array[2], array[3], array[4], total);\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        MPI_Recv(&array, SIZE, MPI_DOUBLE, 0, tag, MPI_COMM_WORLD, &status);\n",
        "\n",
        "        for (int j = 1; j < numberProcess; j++)\n",
        "        {\n",
        "            if (id == j)\n",
        "            {\n",
        "                value = getOperationResult(id, array);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        MPI_Send(&value, 1, MPI_DOUBLE, 0, tag, MPI_COMM_WORLD);\n",
        "    }\n",
        "\n",
        "    MPI_Finalize();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "XDW7hQI48Et2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc algebraic.c -o ob\n",
        "!mpirun --allow-run-as-root --np 4 ./ob "
      ],
      "metadata": {
        "id": "hzJVAGGo2D7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Session 3: Tridiagonal Matrix"
      ],
      "metadata": {
        "id": "BC3y-Is8roOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui apresentamos a solução para a adição de valores da diagonal principal, superdiagonal e subdiagonal de uma matriz.\n"
      ],
      "metadata": {
        "id": "5CjLw3Agwj8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código sequencial."
      ],
      "metadata": {
        "id": "XogoKXooFxXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#define ORDER 4\n",
        "\n",
        "void printMatrix (int m[][ORDER]) {\n",
        "  int i, j;\n",
        "  for(i = 0; i < ORDER; i++) {\n",
        "    printf (\"| \");\n",
        "    for (j = 0; j < ORDER; j++) {\n",
        "      printf (\"%3d \", m[i][j]);\n",
        "    }\n",
        "    printf (\"|\\n\");\n",
        "  }\n",
        "  printf (\"\\n\");\n",
        "}\n",
        "\n",
        "int main (int argc, char **argv){\n",
        "\n",
        "  int k[3] = {100, 200, 300};\n",
        "  int matrix[ORDER][ORDER];\n",
        "  int i, j;\n",
        "\n",
        "  for(i = 0; i < ORDER; i++) {\n",
        "    for(j = 0; j < ORDER; j++) {\n",
        "      if( i == j )\n",
        "        matrix[i][j] = i + j +1;\n",
        "      else if(i == (j + 1)) {\n",
        "        matrix[i][j] = i +  j + 1;\n",
        "        matrix[j][i] = matrix[i][j];\n",
        "      } else\n",
        "           matrix[i][j] = 0;\n",
        "     }\n",
        "  }\n",
        "\n",
        "  printMatrix(matrix);\n",
        "\n",
        "  for(i = 0; i < ORDER; i++){\n",
        "       matrix[i][i]     += k[0];  //main diagonal\n",
        "     matrix[i + 1][i] += k[1];    //subdiagonal\n",
        "     matrix[i][i + 1] += k[2];    //superdiagonal\n",
        "  }\n",
        "\n",
        "  printMatrix(matrix);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "CuWMjvNExTmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc matrix.c -o matrix\n",
        "!./matrix"
      ],
      "metadata": {
        "id": "EF_0kncD0gRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código com a utilização de paralelização usando memória distribuída."
      ],
      "metadata": {
        "id": "HOO5nNyHFnwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix.c\n",
        "#include <stdio.h>\n",
        "#include <mpi.h>\n",
        "#define ORDER 4\n",
        "\n",
        "int matrix[ORDER][ORDER];\n",
        "int ma[ORDER][ORDER]; //matriz auxiliar\n",
        "int k[3] = {100, 200, 300};\n",
        "\n",
        "void printMatrix (int m[][ORDER]) {\n",
        "    int i, j;\n",
        "    for(i = 0; i < ORDER; i++) {\n",
        "    printf (\"| \");\n",
        "    for (j = 0; j < ORDER; j++) {\n",
        "    printf (\"%3d \", m[i][j]);\n",
        "    }\n",
        "    printf (\"|\\n\");\n",
        "    }\n",
        "    printf (\"\\n\");\n",
        "}\n",
        "\n",
        "void getOperationResult(int operation, int m[][ORDER])\n",
        "{\n",
        "    int i;\n",
        "    switch (operation)\n",
        "    {\n",
        "    case 1:\n",
        "        for(i = 0; i < ORDER; i++){\n",
        "          ma[i][i] = m[i][i] + k[0]; //main diagonal\n",
        "        }\n",
        "        break;\n",
        "    case 2:\n",
        "        for(i = 0; i < ORDER; i++){\n",
        "          ma[i + 1][i] = m[i + 1][i] + k[1]; //subdiagonal\n",
        "        }\n",
        "        break;\n",
        "    case 3:\n",
        "        for(i = 0; i < ORDER; i++){\n",
        "          ma[i][i + 1] = m[i][i + 1] + k[2]; //superdiagonal\n",
        "        }\n",
        "        break;\n",
        "    }\n",
        " }\n",
        "\n",
        " void buildMatrix(int operation, int m[][ORDER])\n",
        "{\n",
        "  int i;\n",
        "    switch (operation)\n",
        "    {\n",
        "    case 1:\n",
        "        for(i = 0; i < ORDER; i++){\n",
        "          matrix[i][i] = m[i][i];\n",
        "        }\n",
        "        break;\n",
        "    case 2:\n",
        "        for(i = 0; i < ORDER; i++){\n",
        "          matrix[i + 1][i] = m[i + 1][i];\n",
        "        }\n",
        "        break;\n",
        "    case 3:\n",
        "        for(i = 0; i < ORDER; i++){\n",
        "          matrix[i][i + 1] = m[i][i + 1];\n",
        "        }\n",
        "        break;\n",
        "    }\n",
        " }\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    int i, result[ORDER][ORDER], matrixInit[ORDER][ORDER];\n",
        "    int numberProcess, id, to, from, tag = 1000;\n",
        "\n",
        "    MPI_Init(&argc, &argv);\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &id);\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &numberProcess);\n",
        "    MPI_Status status;\n",
        "\n",
        "    if (id == 0)\n",
        "    {\n",
        "          int i, j;\n",
        "          for(i = 0; i < ORDER; i++) {\n",
        "            for(j = 0; j < ORDER; j++) {\n",
        "            if( i == j )\n",
        "            matrixInit[i][j] = i + j +1;\n",
        "            else if(i == (j + 1)) {\n",
        "            matrixInit[i][j] = i + j + 1;\n",
        "            matrixInit[j][i] = matrixInit[i][j];\n",
        "            } else\n",
        "            matrixInit[i][j] = 0;\n",
        "            }\n",
        "          }\n",
        "          printMatrix(matrixInit);\n",
        "        for (to = 1; to < numberProcess; to++)\n",
        "        {\n",
        "            MPI_Send(&matrixInit, ORDER*ORDER, MPI_INT, to, tag, MPI_COMM_WORLD);\n",
        "        }\n",
        "\n",
        "        for (from = 1; from < numberProcess; from++)\n",
        "        {\n",
        "            MPI_Recv(&result, ORDER*ORDER, MPI_INT, from, tag, MPI_COMM_WORLD, &status);\n",
        "            buildMatrix(from, result);\n",
        "        }\n",
        "        printMatrix(matrix);\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        int matrixSent[ORDER][ORDER];\n",
        "        \n",
        "        MPI_Recv(&matrixSent, ORDER*ORDER, MPI_INT, 0, tag, MPI_COMM_WORLD, &status);\n",
        "        \n",
        "        for (int j = 1; j < numberProcess; j++)\n",
        "        {\n",
        "            if (id == j)\n",
        "            {\n",
        "                getOperationResult(id, matrixSent);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        MPI_Send(&ma, ORDER*ORDER, MPI_INT, 0, tag, MPI_COMM_WORLD);\n",
        "    }\n",
        "\n",
        "    MPI_Finalize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "r0YK2hVIjOjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc matrix.c -o matrix\n",
        "!mpirun --allow-run-as-root --np 4 ./matrix "
      ],
      "metadata": {
        "id": "bSnyOYYW2JwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EkecWU4KKvo"
      },
      "source": [
        "# Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOXpKoRrJ5sm"
      },
      "source": [
        "Com a prática realizada, foi possível observar o impacto que a paralelização dos processos tem sobre um algoritmo de alto custo computacional, como a multiplicação de matrizes. Também observamos a importância de utilizar o melhor número de processos para execução do código a fim de reduzir o tempo de execução, e a instabilidade."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbxAR_nZ3ey8"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHs1Te143ezA"
      },
      "source": [
        "[1] Karniadakis, G., & Kirby II, R. (2003). Parallel Scientific Computing in C and MPI: A Seamless Approach to Parallel Algorithms and their Implementation. Cambridge: Cambridge University Press. doi:10.1017/CBO9780511812583\n",
        "\n",
        "[2] Alessandra Monteleone, Gaetano Burriesci, Enrico Napoli. A distributed-memory MPI parallelization scheme for multi-domain incompressible SPH. Journal of Parallel and Distributed Computing. v. 170, 2022. pp. 53-67, doi:\n",
        "10.1016/j.jpdc.2022.08.004.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}